{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a denoising autoencoder on MNIST dataset.\n",
    "Denoising is one of the classic applications of autoencoders.\n",
    "The denoising process removes unwanted noise that corrupted the\n",
    "true signal.\n",
    "Noise + Data ---> Denoising Autoencoder ---> Data\n",
    "Given a training dataset of corrupted data as input and\n",
    "true signal as output, a denoising autoencoder can recover the\n",
    "hidden structure to generate clean data.\n",
    "This example has modular design. The encoder, decoder and autoencoder\n",
    "are 3 models that share weights. For example, after training the\n",
    "autoencoder, the encoder can be used to  generate latent vectors\n",
    "of input data for low-dim visualization like PCA or TSNE.\n",
    "adapted from https://github.com/keras-team/keras/blob/master/examples/mnist_denoising_autoencoder.py\n",
    "'''\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "Model = tf.keras.models.Model\n",
    "Input = tf.keras.layers.Input\n",
    "Dense = tf.keras.layers.Dense\n",
    "Flatten = tf.keras.layers.Flatten\n",
    "Conv2D = tf.keras.layers.Conv2D \n",
    "MaxPooling2D = tf.keras.layers.MaxPooling2D\n",
    "K = tf.keras.backend\n",
    "Reshape = tf.keras.layers.Reshape\n",
    "Conv2DTranspose = tf.keras.layers.Conv2DTranspose\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-17c15a7236ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Generate corrupted MNIST images by adding noise with normal dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# centered at 0.5 and std=0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mx_train_noisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtest_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.normal\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.cont2_array_sc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_size = x_train.shape[1]\n",
    "#assume channel is third dimension of input\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Generate corrupted MNIST images by adding noise with normal dist\n",
    "# centered at 0.5 and std=0.5\n",
    "train_noise = np.random.normal(loc=0.5, scale=0.5, size=x_train.shape)\n",
    "x_train_noisy = x_train + train_noise\n",
    "test_noise = np.random.normal(loc=0.5, scale=0.5, size=x_test.shape)\n",
    "x_test_noisy = x_test + test_noise\n",
    "\n",
    "#if < 0 -> 0, if > 1 -> 1\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "latent_dim = 16\n",
    "filters1 = 32\n",
    "filters2 = 64\n",
    "stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Autoencoder Model\n",
    "def cnn_encode():\n",
    "    \"\"\"First build the Encoder Model\"\"\"\n",
    "    a0 = Input(shape=input_shape, name='encoder_input')\n",
    "    # Stack of Conv2D blocks\n",
    "    # Notes:\n",
    "    # 1) Use Batch Normalization before ReLU on deep networks\n",
    "    # 2) Use MaxPooling2D as alternative to strides>1\n",
    "    # - faster but not as good as strides>1\n",
    "    a1 = Conv2D(filters=filters1,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=stride,\n",
    "                   activation='relu',\n",
    "                   padding='same')(a0)\n",
    "    a2 = Conv2D(filters=filters2,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=stride,\n",
    "                   activation='relu',\n",
    "                   padding='same')(a1)\n",
    "    \n",
    "\n",
    "    # Shape info needed to build Decoder Model\n",
    "    a2_shape = K.int_shape(a2)\n",
    "\n",
    "    # Generate the latent vector (encoding)\n",
    "    a2 = Flatten()(a2)\n",
    "    latent = Dense(latent_dim, name='latent_vector')(a2) \n",
    "    return Model(inputs = a0, outputs = latent, name='encoder'), a2_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Encoder Model\n",
    "encoder, a2_shape = cnn_encode()\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_decode():\n",
    "    \"\"\"Next build the Decoder Model\"\"\"\n",
    "    latent = Input(shape=(latent_dim,), name='decoder_input')\n",
    "    a2 = Dense(a2_shape[1] * a2_shape[2] * a2_shape[3])(latent)\n",
    "    a2 = Reshape((a2_shape[1], a2_shape[2], a2_shape[3]))(a2)\n",
    "    a1 = Conv2DTranspose(filters=filters2,\n",
    "                        kernel_size=kernel_size,\n",
    "                        strides=stride,\n",
    "                        activation='relu',\n",
    "                        padding='same')(a2)\n",
    "    a0 = Conv2DTranspose(filters=filters1,\n",
    "                        kernel_size=kernel_size,\n",
    "                        strides=stride,\n",
    "                        activation='relu',\n",
    "                        padding='same')(a1)\n",
    "    output = Conv2DTranspose(filters=1,\n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same',\n",
    "                        activation = 'sigmoid')(a0)\n",
    "    return Model(inputs = latent, outputs = output, name = 'decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Decoder Model\n",
    "decoder = cnn_decode()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder = Encoder + Decoder\n",
    "# Instantiate Autoencoder Model\n",
    "#encoder.input returns a0 tensor\n",
    "#encoder(encoder.input) returns latent tensor\n",
    "#decoder(encoder(encoder.input)) returns output tensor\n",
    "autoencoder = Model(inputs = encoder.input, outputs = decoder(encoder(encoder.input)), name='autoencoder')\n",
    "autoencoder.summary()\n",
    "autoencoder.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fadb8be7b26b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the autoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m autoencoder.fit(x_train_noisy,\n\u001b[0m\u001b[1;32m      3\u001b[0m                 \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_noisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "autoencoder.fit(x_train_noisy,\n",
    "                x_train,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                epochs=1,\n",
    "                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-db3d6d054cec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict the Autoencoder output from corrupted test images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_noisy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict the Autoencoder output from corrupted test images\n",
    "x_decoded = autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 1st 8 corrupted and denoised images\n",
    "rows, cols = 10, 30\n",
    "num = rows * cols\n",
    "imgs = np.concatenate([x_test[:num], x_test_noisy[:num], x_decoded[:num]])\n",
    "imgs = imgs.reshape((rows * 3, cols, image_size, image_size))\n",
    "imgs = np.vstack(np.split(imgs, rows, axis=1))\n",
    "imgs = imgs.reshape((rows * 3, -1, image_size, image_size))\n",
    "imgs = np.vstack([np.hstack(i) for i in imgs])\n",
    "imgs = (imgs * 255).astype(np.uint8)\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.title('Original images: top rows, '\n",
    "          'Corrupted Input: middle rows, '\n",
    "          'Denoised Input:  third rows')\n",
    "plt.imshow(imgs, interpolation='none', cmap='gray')\n",
    "Image.fromarray(imgs).save('corrupted_and_denoised.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
