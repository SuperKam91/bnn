{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "adapted from https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "'''\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "Model = tf.keras.models.Model\n",
    "Input = tf.keras.layers.Input\n",
    "Dense = tf.keras.layers.Dense\n",
    "Dropout = tf.keras.layers.Dropout\n",
    "Flatten = tf.keras.layers.Flatten\n",
    "Conv2D = tf.keras.layers.Conv2D \n",
    "MaxPooling2D = tf.keras.layers.MaxPooling2D\n",
    "K = tf.keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add channel dimension\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    inp_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "inp_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model1():\n",
    "    \"\"\"\n",
    "    keras model builder (using model api) for cnn for mnist classification.\n",
    "    same one used in official tf example.\n",
    "    roughly 2 million trainable parameters.\n",
    "    99.25% accuracy on test data after 12 epochs.\n",
    "    \"\"\"\n",
    "    a0 = Input(shape=inp_shape)\n",
    "    a1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(a0)\n",
    "    a2 = Conv2D(64, (3, 3), activation='relu')(a1)\n",
    "    a2 = MaxPooling2D(pool_size=(2, 2))(a2)\n",
    "    a2 = Dropout(0.25)(a2)\n",
    "    a2 = Flatten()(a2)\n",
    "    a3 = Dense(128, activation='relu')(a2)\n",
    "    a3 = Dropout(0.5)(a3)\n",
    "    prediction = Dense(num_classes, activation='softmax')(a3)\n",
    "    return Model(inputs = a0, outputs = prediction)\n",
    "\n",
    "def cnn_model2():\n",
    "    \"\"\"\n",
    "    same as cnn_model1 but without dense layer, subsequent dropout, and with weights of output (softmax) layer frozen.\n",
    "    roughly 20k trainable parameters, and 100k not trained.\n",
    "    91% accuracy on test data after 12 epochs.\n",
    "    \"\"\"\n",
    "    a0 = Input(shape=inp_shape)\n",
    "    a1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(a0)\n",
    "    a2 = Conv2D(64, (3, 3), activation='relu')(a1)\n",
    "    a2 = MaxPooling2D(pool_size=(2, 2))(a2)\n",
    "    a2 = Dropout(0.25)(a2)\n",
    "    a2 = Flatten()(a2)\n",
    "    prediction = Dense(num_classes, activation='softmax', trainable = False)(a2)\n",
    "    return Model(inputs = a0, outputs = prediction)\n",
    "\n",
    "def cnn_model3():\n",
    "    \"\"\"\n",
    "    same as cnn_model2 but with number of convolutional filters reduced to make flattened layer smaller, \n",
    "    and crucially, weights of output aren't frozen.\n",
    "    roughly 25k trainable parameters.\n",
    "    98.5% accuracy on test data after 12 epochs.\n",
    "    \"\"\"\n",
    "    a0 = Input(shape=inp_shape)\n",
    "    a1 = Conv2D(8, kernel_size=(3, 3), activation='relu')(a0)\n",
    "    a2 = Conv2D(16, (3, 3), activation='relu')(a1)\n",
    "    a2 = MaxPooling2D(pool_size=(2, 2))(a2)\n",
    "    a2 = Dropout(0.25)(a2)\n",
    "    a2 = Flatten()(a2)\n",
    "    prediction = Dense(num_classes, activation='softmax')(a2)\n",
    "    return Model(inputs = a0, outputs = prediction)\n",
    "\n",
    "def cnn_model4():\n",
    "    \"\"\"\n",
    "    same as cnn_model3 but with number of convolutional filters reduced to make flattened layer smaller. \n",
    "    roughly 12k trainable parameters.\n",
    "    97.8% accuracy on test data after 12 epochs.\n",
    "    \"\"\"\n",
    "    a0 = Input(shape=inp_shape)\n",
    "    a1 = Conv2D(4, kernel_size=(3, 3), activation='relu')(a0)\n",
    "    a2 = Conv2D(8, (3, 3), activation='relu')(a1)\n",
    "    a2 = MaxPooling2D(pool_size=(2, 2))(a2)\n",
    "    a2 = Dropout(0.25)(a2)\n",
    "    a2 = Flatten()(a2)\n",
    "    prediction = Dense(num_classes, activation='softmax')(a2)\n",
    "    return Model(inputs = a0, outputs = prediction)\n",
    "\n",
    "def cnn_model5():\n",
    "    \"\"\"\n",
    "    same as cnn_model4 but with max pooling with pool size = 4 x 4. \n",
    "    roughly 3k trainable parameters.\n",
    "    97.4% accuracy on test data after 12 epochs.\n",
    "    \"\"\"\n",
    "    a0 = Input(shape=inp_shape)\n",
    "    a1 = Conv2D(4, kernel_size=(3, 3), activation='relu')(a0)\n",
    "    a2 = Conv2D(8, (3, 3), activation='relu')(a1)\n",
    "    a2 = MaxPooling2D(pool_size=(4, 4))(a2)\n",
    "    a2 = Dropout(0.25)(a2)\n",
    "    a2 = Flatten()(a2)\n",
    "    prediction = Dense(num_classes, activation='softmax')(a2)\n",
    "    return Model(inputs = a0, outputs = prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = cnn_model1()\n",
    "model1.summary()\n",
    "model1.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = cnn_model2()\n",
    "model2.summary()\n",
    "model2.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = cnn_model3()\n",
    "model3.summary()\n",
    "model3.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 26, 26, 4)         40        \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 24, 24, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                11530     \n",
      "=================================================================\n",
      "Total params: 11,866\n",
      "Trainable params: 11,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = cnn_model4()\n",
    "model4.summary()\n",
    "model4.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 26, 26, 4)         40        \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 24, 24, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 6, 6, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 6, 6, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                2890      \n",
      "=================================================================\n",
      "Total params: 3,226\n",
      "Trainable params: 3,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = cnn_model5()\n",
    "model5.summary()\n",
    "model5.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model1.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 111s 2ms/step - loss: 0.4462 - acc: 0.8667 - val_loss: 0.1565 - val_acc: 0.9554\n",
      "\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 106s 2ms/step - loss: 0.1641 - acc: 0.9520 - val_loss: 0.1042 - val_acc: 0.9696\n",
      "\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 108s 2ms/step - loss: 0.1254 - acc: 0.9629 - val_loss: 0.0842 - val_acc: 0.9759\n",
      "\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 106s 2ms/step - loss: 0.1091 - acc: 0.9676 - val_loss: 0.0728 - val_acc: 0.9789\n",
      "\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 107s 2ms/step - loss: 0.0979 - acc: 0.9712 - val_loss: 0.0663 - val_acc: 0.9801\n",
      "\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 106s 2ms/step - loss: 0.0899 - acc: 0.9729 - val_loss: 0.0610 - val_acc: 0.9814\n",
      "\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 106s 2ms/step - loss: 0.0837 - acc: 0.9748 - val_loss: 0.0571 - val_acc: 0.9823\n",
      "\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 107s 2ms/step - loss: 0.0781 - acc: 0.9762 - val_loss: 0.0558 - val_acc: 0.9835\n",
      "\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 107s 2ms/step - loss: 0.0749 - acc: 0.9773 - val_loss: 0.0530 - val_acc: 0.9837\n",
      "\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 107s 2ms/step - loss: 0.0708 - acc: 0.9784 - val_loss: 0.0494 - val_acc: 0.9851\n",
      "\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 106s 2ms/step - loss: 0.0681 - acc: 0.9798 - val_loss: 0.0471 - val_acc: 0.9859\n",
      "\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 106s 2ms/step - loss: 0.0652 - acc: 0.9800 - val_loss: 0.0468 - val_acc: 0.9856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 79s 1ms/step - loss: 0.5723 - acc: 0.8281 - val_loss: 0.2491 - val_acc: 0.9320\n",
      "\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 71s 1ms/step - loss: 0.2768 - acc: 0.9174 - val_loss: 0.1999 - val_acc: 0.9444\n",
      "\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 63s 1ms/step - loss: 0.2375 - acc: 0.9296 - val_loss: 0.1705 - val_acc: 0.9520\n",
      "\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 67s 1ms/step - loss: 0.2091 - acc: 0.9388 - val_loss: 0.1512 - val_acc: 0.9566\n",
      "\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 68s 1ms/step - loss: 0.1878 - acc: 0.9451 - val_loss: 0.1312 - val_acc: 0.9617\n",
      "\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 63s 1ms/step - loss: 0.1662 - acc: 0.9509 - val_loss: 0.1160 - val_acc: 0.9663\n",
      "\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 58s 961us/step - loss: 0.1509 - acc: 0.9559 - val_loss: 0.1048 - val_acc: 0.9693\n",
      "\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 58s 970us/step - loss: 0.1393 - acc: 0.9590 - val_loss: 0.0952 - val_acc: 0.9715\n",
      "\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 62s 1ms/step - loss: 0.1291 - acc: 0.9618 - val_loss: 0.0888 - val_acc: 0.9727\n",
      "\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 76s 1ms/step - loss: 0.1198 - acc: 0.9650 - val_loss: 0.0820 - val_acc: 0.9749\n",
      "\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 67s 1ms/step - loss: 0.1151 - acc: 0.9654 - val_loss: 0.0781 - val_acc: 0.9761\n",
      "\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 68s 1ms/step - loss: 0.1053 - acc: 0.9683 - val_loss: 0.0735 - val_acc: 0.9781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 73s 1ms/step - loss: 0.8870 - acc: 0.7106 - val_loss: 0.2301 - val_acc: 0.9340\n",
      "\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 61s 1ms/step - loss: 0.2958 - acc: 0.9083 - val_loss: 0.1624 - val_acc: 0.9547\n",
      "\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 58s 969us/step - loss: 0.2355 - acc: 0.9277 - val_loss: 0.1405 - val_acc: 0.9592\n",
      "\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 89s 1ms/step - loss: 0.2095 - acc: 0.9344 - val_loss: 0.1282 - val_acc: 0.9627\n",
      "\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 75s 1ms/step - loss: 0.1897 - acc: 0.9410 - val_loss: 0.1177 - val_acc: 0.9655\n",
      "\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 71s 1ms/step - loss: 0.1794 - acc: 0.9446 - val_loss: 0.1091 - val_acc: 0.9672\n",
      "\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 84s 1ms/step - loss: 0.1687 - acc: 0.9477 - val_loss: 0.1032 - val_acc: 0.9687\n",
      "\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 79s 1ms/step - loss: 0.1626 - acc: 0.9497 - val_loss: 0.0995 - val_acc: 0.9702\n",
      "\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 64s 1ms/step - loss: 0.1552 - acc: 0.9532 - val_loss: 0.0943 - val_acc: 0.9722\n",
      "\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 65s 1ms/step - loss: 0.1519 - acc: 0.9525 - val_loss: 0.0917 - val_acc: 0.9731\n",
      "\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 65s 1ms/step - loss: 0.1445 - acc: 0.9552 - val_loss: 0.0893 - val_acc: 0.9730\n",
      "\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 64s 1ms/step - loss: 0.1438 - acc: 0.9559 - val_loss: 0.0863 - val_acc: 0.9739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history5 = model5.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = model1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss for model1:', score1[0])\n",
    "print('Test accuracy for model1:', score1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss for model2:', score2[0])\n",
    "print('Test accuracy for model2:', score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 0.04675232584038749)\n",
      "('Test accuracy:', 0.9856)\n"
     ]
    }
   ],
   "source": [
    "score3 = model3.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss for model3:', score3[0])\n",
    "print('Test accuracy for model3:', score3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss for model4:', 0.07353736386187375)\n",
      "('Test accuracy for model4:', 0.9781)\n"
     ]
    }
   ],
   "source": [
    "score4 = model4.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss for model4:', score4[0])\n",
    "print('Test accuracy for model4:', score4[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss for model5:', 0.08627387657612562)\n",
      "('Test accuracy for model5:', 0.9739)\n"
     ]
    }
   ],
   "source": [
    "score5 = model5.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss for model5:', score5[0])\n",
    "print('Test accuracy for model5:', score5[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
