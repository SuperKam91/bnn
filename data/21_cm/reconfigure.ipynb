{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 1\n",
    "#original method, takes their splits, transforms from timeseries to individual datapoints, \n",
    "#then combines to make full dataset. to be used with first method in 21_preprocessing.ipynb,\n",
    "#where shuffling for tr/cv/te takes places over all datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21562, 136)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d912c4ca071f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mpars_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mfull_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpars_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwenty_ones_tr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'8_params_21_tr.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtwenty_one_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'T21_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_090219.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1425\u001b[0m                                     \u001b[0;34m\"format specifier ('%s')\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m                                     % (str(X.dtype), format))\n\u001b[0;32m-> 1427\u001b[0;31m                 \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfooter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mwrite_normal\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrite_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masunicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfirst_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/compat/py3k.pyc\u001b[0m in \u001b[0;36masunicode\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_latin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "splits = ['train', 'test']\n",
    "z = np.genfromtxt('zData_090219.txt')\n",
    "n_z = len(z)\n",
    "#training data\n",
    "twenty_one_tr = np.genfromtxt('T21_' + splits[0] + '_090219.txt')\n",
    "twenty_ones_tr = twenty_one_tr.reshape(-1, 1)\n",
    "zs_tr = np.stack([z for _ in range(twenty_one_tr.shape[0])], axis=0).reshape(-1, 1)\n",
    "par_tr = np.genfromtxt('Par_' + splits[0] + '_090219.txt')\n",
    "pars_tr = np.repeat(par_tr, n_z, axis=0)\n",
    "full_tr = np.hstack([pars_tr, zs_tr, twenty_ones_tr])\n",
    "np.savetxt('8_params_21_tr.txt', full_tr, delimiter = ' ')\n",
    "#test data\n",
    "twenty_one_te = np.genfromtxt('T21_' + splits[1] + '_090219.txt')\n",
    "twenty_ones_te = twenty_one_te.reshape(-1, 1)\n",
    "zs_te = np.stack([z for _ in range(twenty_one_te.shape[0])], axis=0).reshape(-1, 1)\n",
    "par_te = np.genfromtxt('Par_' + splits[1] + '_090219.txt')\n",
    "pars_te = np.repeat(par_te, n_z, axis=0)\n",
    "full_te = np.hstack([pars_te, zs_te, twenty_ones_te])\n",
    "np.savetxt('8_params_21_te.txt', full_te, delimiter = ' ')\n",
    "full = np.vstack([full_tr, full_te])\n",
    "np.savetxt('8_params_21.txt', full, delimiter = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 2\n",
    "#take paper's tr/te splits, and split their tr into tr and cv split. shuffles over timeseries rather than datapoints\n",
    "#to be used with method 2 in 21_preprocessing.ipynb, where it is assumed that shuffling has already occurred.\n",
    "#note values of alpha and nu_min are CONSTANT across tr/te splits given by authors, \n",
    "#meaning their variance is 0, and sk learn's standard scaler screws up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['train', 'test']\n",
    "z = np.genfromtxt('zData_090219.txt')\n",
    "n_z = len(z)\n",
    "#training data\n",
    "twenty_one_tr = np.genfromtxt('T21_' + splits[0] + '_090219.txt')\n",
    "par_tr = np.genfromtxt('Par_' + splits[0] + '_090219.txt')\n",
    "##########################################\n",
    "#this value needs to be copied to 21_preprocessing.ipynb\n",
    "cv_size = 0.\n",
    "##########################################par_tr, par_cv, twenty_one_tr, twenty_one_cv = sklearn.model_selection.train_test_split(par_tr, twenty_one_tr, test_size = cv_size)\n",
    "twenty_ones_tr = twenty_one_tr.reshape(-1, 1)\n",
    "zs_tr = np.stack([z for _ in range(twenty_one_tr.shape[0])], axis=0).reshape(-1, 1)\n",
    "pars_tr = np.repeat(par_tr, n_z, axis=0)\n",
    "full_tr = np.hstack([pars_tr, zs_tr, twenty_ones_tr])\n",
    "np.savetxt('8_params_21_2_tr.txt', full_tr, delimiter = ' ')\n",
    "if cv_size:\n",
    "    #cv data\n",
    "    twenty_ones_cv = twenty_one_cv.reshape(-1, 1)\n",
    "    zs_cv = np.stack([z for _ in range(twenty_one_cv.shape[0])], axis=0).reshape(-1, 1)\n",
    "    pars_cv = np.repeat(par_cv, n_z, axis=0)\n",
    "    full_cv = np.hstack([pars_cv, zs_cv, twenty_ones_cv])\n",
    "    np.savetxt('8_params_21_2_cv.txt', full_tr, delimiter = ' ')\n",
    "#test data\n",
    "twenty_one_te = np.genfromtxt('T21_' + splits[1] + '_090219.txt')\n",
    "twenty_ones_te = twenty_one_te.reshape(-1, 1)\n",
    "zs_te = np.stack([z for _ in range(twenty_one_te.shape[0])], axis=0).reshape(-1, 1)\n",
    "par_te = np.genfromtxt('Par_' + splits[1] + '_090219.txt')\n",
    "pars_te = np.repeat(par_te, n_z, axis=0)\n",
    "full_te = np.hstack([pars_te, zs_te, twenty_ones_te])\n",
    "np.savetxt('8_params_21_2_te.txt', full_te, delimiter = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 3\n",
    "#take paper's tr/te splits and combines them, then splits into tr, cv and te split. \n",
    "#like method 2, shuffles over timeseries rather than datapoints\n",
    "#to be used with method 3 in 21_preprocessing.ipynb, where it is assumed that shuffling has already occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['train', 'test']\n",
    "z = np.genfromtxt('zData_090219.txt')\n",
    "n_z = len(z)\n",
    "#training data\n",
    "twenty_one_tr = np.genfromtxt('T21_' + splits[0] + '_090219.txt')\n",
    "par_tr = np.genfromtxt('Par_' + splits[0] + '_090219.txt')\n",
    "full_tr = np.hstack([par_tr, twenty_one_tr])\n",
    "twenty_one_te = np.genfromtxt('T21_' + splits[1] + '_090219.txt')\n",
    "par_te = np.genfromtxt('Par_' + splits[1] + '_090219.txt')\n",
    "full_te = np.hstack([par_te, twenty_one_te])\n",
    "par = np.vstack([par_tr, par_te])\n",
    "twenty_one = np.vstack([twenty_one_tr, twenty_one_te])\n",
    "np.savetxt('Par_090219.txt', par, delimiter = ' ')\n",
    "np.savetxt('T21_090219.txt', twenty_one, delimiter = ' ')\n",
    "seed_n = 1\n",
    "np.random.seed(seed_n)\n",
    "te_size = 1. * par_te.shape[0] / (par_te.shape[0] + par_tr.shape[0])\n",
    "par_tr, par_te, twenty_one_tr, twenty_one_te = sklearn.model_selection.train_test_split(par, twenty_one, test_size = te_size)\n",
    "##########################################\n",
    "#this value needs to be copied to 21_preprocessing.ipynb\n",
    "cv_size = 0.\n",
    "##########################################\n",
    "par_tr, par_cv, twenty_one_tr, twenty_one_cv = sklearn.model_selection.train_test_split(par_tr, twenty_one_tr, test_size = cv_size)\n",
    "twenty_ones_tr = twenty_one_tr.reshape(-1, 1)\n",
    "zs_tr = np.stack([z for _ in range(twenty_one_tr.shape[0])], axis=0).reshape(-1, 1)\n",
    "pars_tr = np.repeat(par_tr, n_z, axis=0)\n",
    "full_tr = np.hstack([pars_tr, zs_tr, twenty_ones_tr])\n",
    "np.savetxt('8_params_21_3_tr.txt', full_tr, delimiter = ' ')\n",
    "if cv_size:\n",
    "    #cv data\n",
    "    twenty_ones_cv = twenty_one_cv.reshape(-1, 1)\n",
    "    zs_cv = np.stack([z for _ in range(twenty_one_cv.shape[0])], axis=0).reshape(-1, 1)\n",
    "    pars_cv = np.repeat(par_cv, n_z, axis=0)\n",
    "    full_cv = np.hstack([pars_cv, zs_cv, twenty_ones_cv])\n",
    "    np.savetxt('8_params_21_3_cv.txt', full_tr, delimiter = ' ')\n",
    "#test data\n",
    "twenty_ones_te = twenty_one_te.reshape(-1, 1)\n",
    "zs_te = np.stack([z for _ in range(twenty_one_te.shape[0])], axis=0).reshape(-1, 1)\n",
    "pars_te = np.repeat(par_te, n_z, axis=0)\n",
    "full_te = np.hstack([pars_te, zs_te, twenty_ones_te])\n",
    "np.savetxt('8_params_21_3_te.txt', full_te, delimiter = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
