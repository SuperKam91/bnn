{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/astrophysics/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "'''Trains a denoising autoencoder on MNIST dataset.\n",
    "Denoising is one of the classic applications of autoencoders.\n",
    "The denoising process removes unwanted noise that corrupted the\n",
    "true signal.\n",
    "Noise + Data ---> Denoising Autoencoder ---> Data\n",
    "Given a training dataset of corrupted data as input and\n",
    "true signal as output, a denoising autoencoder can recover the\n",
    "hidden structure to generate clean data.\n",
    "This example has modular design. The encoder, decoder and autoencoder\n",
    "are 3 models that share weights. For example, after training the\n",
    "autoencoder, the encoder can be used to  generate latent vectors\n",
    "of input data for low-dim visualization like PCA or TSNE.\n",
    "adapted from https://github.com/keras-team/keras/blob/master/examples/mnist_denoising_autoencoder.py\n",
    "'''\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "Model = tf.keras.models.Model\n",
    "Input = tf.keras.layers.Input\n",
    "Dense = tf.keras.layers.Dense\n",
    "Flatten = tf.keras.layers.Flatten\n",
    "Conv2D = tf.keras.layers.Conv2D \n",
    "MaxPooling2D = tf.keras.layers.MaxPooling2D\n",
    "K = tf.keras.backend\n",
    "Reshape = tf.keras.layers.Reshape\n",
    "Conv2DTranspose = tf.keras.layers.Conv2DTranspose\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = x_train.shape[1]\n",
    "#assume channel is third dimension of input\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Generate corrupted MNIST images by adding noise with normal dist\n",
    "# centered at 0.5 and std=0.5\n",
    "train_noise = np.random.normal(loc=0.5, scale=0.5, size=x_train.shape)\n",
    "x_train_noisy = x_train + train_noise\n",
    "test_noise = np.random.normal(loc=0.5, scale=0.5, size=x_test.shape)\n",
    "x_test_noisy = x_test + test_noise\n",
    "\n",
    "#if < 0 -> 0, if > 1 -> 1\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "latent_dim = 16\n",
    "filters1 = 32\n",
    "filters2 = 64\n",
    "stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Autoencoder Model\n",
    "def cnn_encode():\n",
    "    \"\"\"First build the Encoder Model\"\"\"\n",
    "    a0 = Input(shape=input_shape, name='encoder_input')\n",
    "    # Stack of Conv2D blocks\n",
    "    # Notes:\n",
    "    # 1) Use Batch Normalization before ReLU on deep networks\n",
    "    # 2) Use MaxPooling2D as alternative to strides>1\n",
    "    # - faster but not as good as strides>1\n",
    "    a1 = Conv2D(filters=filters1,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=stride,\n",
    "                   activation='relu',\n",
    "                   padding='same')(a0)\n",
    "    a2 = Conv2D(filters=filters2,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=stride,\n",
    "                   activation='relu',\n",
    "                   padding='same')(a1)\n",
    "    \n",
    "\n",
    "    # Shape info needed to build Decoder Model\n",
    "    a2_shape = K.int_shape(a2)\n",
    "\n",
    "    # Generate the latent vector (encoding)\n",
    "    a2 = Flatten()(a2)\n",
    "    latent = Dense(latent_dim, name='latent_vector')(a2) \n",
    "    return Model(inputs = a0, outputs = latent, name='encoder'), a2_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "latent_vector (Dense)        (None, 16)                50192     \n",
      "=================================================================\n",
      "Total params: 69,008\n",
      "Trainable params: 69,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Encoder Model\n",
    "encoder, a2_shape = cnn_encode()\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_decode():\n",
    "    \"\"\"Next build the Decoder Model\"\"\"\n",
    "    latent = Input(shape=(latent_dim,), name='decoder_input')\n",
    "    a2 = Dense(a2_shape[1] * a2_shape[2] * a2_shape[3])(latent)\n",
    "    a2 = Reshape((a2_shape[1], a2_shape[2], a2_shape[3]))(a2)\n",
    "    a1 = Conv2DTranspose(filters=filters2,\n",
    "                        kernel_size=kernel_size,\n",
    "                        strides=stride,\n",
    "                        activation='relu',\n",
    "                        padding='same')(a2)\n",
    "    a0 = Conv2DTranspose(filters=filters1,\n",
    "                        kernel_size=kernel_size,\n",
    "                        strides=stride,\n",
    "                        activation='relu',\n",
    "                        padding='same')(a1)\n",
    "    output = Conv2DTranspose(filters=1,\n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same',\n",
    "                        activation = 'sigmoid')(a0)\n",
    "    return Model(inputs = latent, outputs = output, name = 'decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3136)              53312     \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 108,993\n",
      "Trainable params: 108,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Decoder Model\n",
    "decoder = cnn_decode()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 16)                69008     \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         108993    \n",
      "=================================================================\n",
      "Total params: 178,001\n",
      "Trainable params: 178,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/astrophysics/anaconda2/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder = Encoder + Decoder\n",
    "# Instantiate Autoencoder Model\n",
    "#encoder.input returns a0 tensor\n",
    "#encoder(encoder.input) returns latent tensor\n",
    "#decoder(encoder(encoder.input)) returns output tensor\n",
    "autoencoder = Model(inputs = encoder.input, outputs = decoder(encoder(encoder.input)), name='autoencoder')\n",
    "autoencoder.summary()\n",
    "autoencoder.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 412s 7ms/step - loss: 0.0608 - val_loss: 0.0388\n",
      "\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 455s 8ms/step - loss: 0.0308 - val_loss: 0.0260\n",
      "\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 445s 7ms/step - loss: 0.0246 - val_loss: 0.0228\n",
      "\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 468s 8ms/step - loss: 0.0222 - val_loss: 0.0209\n",
      "\n",
      "Epoch 5/10\n",
      " 4864/60000 [=>............................] 4864/60000 [=>............................] - ETA: 6:23 - loss: 0.0210"
     ]
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "autoencoder.fit(x_train_noisy,\n",
    "                x_train,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                epochs=10,\n",
    "                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Autoencoder output from corrupted test images\n",
    "x_decoded = autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 1st 8 corrupted and denoised images\n",
    "rows, cols = 10, 30\n",
    "num = rows * cols\n",
    "imgs = np.concatenate([x_test[:num], x_test_noisy[:num], x_decoded[:num]])\n",
    "imgs = imgs.reshape((rows * 3, cols, image_size, image_size))\n",
    "imgs = np.vstack(np.split(imgs, rows, axis=1))\n",
    "imgs = imgs.reshape((rows * 3, -1, image_size, image_size))\n",
    "imgs = np.vstack([np.hstack(i) for i in imgs])\n",
    "imgs = (imgs * 255).astype(np.uint8)\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.title('Original images: top rows, '\n",
    "          'Corrupted Input: middle rows, '\n",
    "          'Denoised Input:  third rows')\n",
    "plt.imshow(imgs, interpolation='none', cmap='gray')\n",
    "Image.fromarray(imgs).save('corrupted_and_denoised.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
