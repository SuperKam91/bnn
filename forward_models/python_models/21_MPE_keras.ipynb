{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_losses as kl\n",
    "import numpy as np\n",
    "import metrics as mets\n",
    "import keras_tools as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "x_train = np.genfromtxt(\"../../data/21_cm/8_params_21_2_x_tr.csv\", delimiter=\",\")\n",
    "y_train = np.genfromtxt(\"../../data/21_cm/8_params_21_2_y_tr.csv\", delimiter=\",\")\n",
    "y_train = y_train.reshape(-1,1) #keras outputs y_pred as 2d, so make y_true 2d as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#architecture parameters\n",
    "num_inputs = x_train.shape[1] #aka n in ml terminology\n",
    "num_outputs = y_train.shape[1] #dimensionality of output y (for single record)\n",
    "layer_sizes = [32, 64, 64, 32]\n",
    "#propagation parameters\n",
    "epochs = 100\n",
    "m = x_train.shape[0] #total number of records\n",
    "batch_num = m / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = tf.keras.models.Model\n",
    "Input = tf.keras.layers.Input\n",
    "Dense = tf.keras.layers.Dense\n",
    "Dropout = tf.keras.layers.Dropout\n",
    "Batch_norm = tf.keras.layers.BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp networks\n",
    "#create model\n",
    "def mlp_drop_norm(num_inputs, num_outputs, layer_sizes):\n",
    "    \"\"\"\n",
    "    arbitrary sized mlp with tanh activation, dropout, batch norm\n",
    "    \"\"\"\n",
    "    dropout_reg = 0.00001\n",
    "    a0 = Input(shape = (num_inputs,))\n",
    "    inputs = a0\n",
    "    for layer_size in layer_sizes:\n",
    "        outputs = Dense(layer_size, activation = 'tanh')(a0)\n",
    "        outputs = Dropout(dropout_reg)(outputs)\n",
    "        outputs = Batch_norm()(outputs)\n",
    "        a0 = outputs\n",
    "    #don't want dropout and normalisation for output layer. linear activation\n",
    "    outputs = Dense(num_outputs, activation = 'linear')(a0)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    return model\n",
    "\n",
    "def mlp_norm(num_inputs, num_outputs, layer_sizes):\n",
    "    \"\"\"\n",
    "    arbitrary sized mlp with tanh activation, batch norm\n",
    "    \"\"\"\n",
    "    a0 = Input(shape = (num_inputs,))\n",
    "    inputs = a0\n",
    "    for layer_size in layer_sizes:\n",
    "        outputs = Dense(layer_size, activation = 'tanh')(a0)\n",
    "        outputs = Batch_norm()(outputs)\n",
    "        a0 = outputs\n",
    "    #don't want normalisation for output layer. linear activation\n",
    "    outputs = Dense(num_outputs, activation = 'linear')(a0)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    return model\n",
    "\n",
    "def mlp(num_inputs, num_outputs, layer_sizes):\n",
    "    \"\"\"\n",
    "    arbitrary sized mlp with tanh activation\n",
    "    \"\"\"\n",
    "    a0 = Input(shape = (num_inputs,))\n",
    "    inputs = a0\n",
    "    for layer_size in layer_sizes:\n",
    "        outputs = Dense(layer_size, activation = 'tanh')(a0)\n",
    "        a0 = outputs\n",
    "    #linear activation for output layer\n",
    "    outputs = Dense(num_outputs, activation = 'linear')(a0)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet networks\n",
    "def uap_mlp_ResNet_block(num_inputs, a0):\n",
    "    \"\"\"\n",
    "    copied from keras_models.py\n",
    "    \"\"\"\n",
    "    a1 = Dense(1, activation = 'relu')(a0)\n",
    "    a2_part = Dense(num_inputs, activation = 'linear', use_bias = False)(a1)\n",
    "    return tf.keras.layers.Add()([a0, a2_part])\n",
    "\n",
    "def coursera_mlp_ResNet_block(num_inputs, a0):\n",
    "    \"\"\"\n",
    "    copied from keras_models.py\n",
    "    \"\"\"\n",
    "    a1 = Dense(1, activation = 'relu')(a0)\n",
    "    z2_part = Dense(num_inputs, activation = 'linear')(a1)\n",
    "    z2 = tf.keras.layers.Add()([a0, z2_part])\n",
    "    return tf.keras.layers.Activation('relu')(z2)\n",
    "\n",
    "def same_mlp_ResNet_block(num_inputs, a0):\n",
    "    \"\"\"\n",
    "    copied from keras_models.py\n",
    "    \"\"\"\n",
    "    a1 = Dense(num_inputs, activation = 'relu')(a0)\n",
    "    z2_part = Dense(num_inputs, activation = 'linear')(a1)\n",
    "    z2 = tf.keras.layers.Add()([a0, z2_part])\n",
    "    return tf.keras.layers.Activation('relu')(z2)\n",
    "\n",
    "def mlp_ResNet_1(num_inputs, num_outputs, layer_sizes, ResNet_type = 'uap'):\n",
    "    \"\"\"\n",
    "    all layers are size of input of nn, apart from final layer which obvs conforms to output\n",
    "    \"\"\"\n",
    "    num_blocks = 4\n",
    "    if ResNet_type == 'uap':\n",
    "        ResNet_block = uap_mlp_ResNet_block\n",
    "    elif ResNet_type == 'coursera':\n",
    "        ResNet_block = coursera_mlp_ResNet_block\n",
    "    elif ResNet_type == 'same':\n",
    "        ResNet_block = same_mlp_ResNet_block\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    a0 = Input(shape = (num_inputs,))\n",
    "    inputs = a0\n",
    "    for _ in range(num_blocks):\n",
    "        a2 = ResNet_block(num_inputs, a0)\n",
    "        a0 = a2\n",
    "    outputs = Dense(num_outputs, activation = 'linear')(a0)\n",
    "    return Model(inputs = inputs, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp(num_inputs, num_outputs, layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = -50.35104929 \n",
    "var = 5410.76986054\n",
    "n_z = 136\n",
    "twenty_one_err_met = kl.twenty_one_cm_rmse_higher_order(mean, var)\n",
    "twenty_one_err_met_ts = kl.twenty_one_cm_rmse_higher_order_ts_mean(mean, var, n_z, m) #won't work, too computationally expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 8,673\n",
      "Trainable params: 8,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.summary()\n",
    "model.compile(optimizer=adam,\n",
    "              loss=['mean_squared_error'],\n",
    "              metrics=[twenty_one_err_met])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2932432/2932432 [==============================] - 5s 2us/step - loss: 1.4487 - twenty_one_cm_rmse: 0.2086\n",
      "Epoch 2/100\n",
      "2932432/2932432 [==============================] - 4s 1us/step - loss: 1.0535 - twenty_one_cm_rmse: 0.1857\n",
      "Epoch 3/100\n",
      "2932432/2932432 [==============================] - 4s 1us/step - loss: 1.0270 - twenty_one_cm_rmse: 0.1658\n",
      "Epoch 4/100\n",
      "2932432/2932432 [==============================] - 4s 2us/step - loss: 0.9759 - twenty_one_cm_rmse: 0.1617\n",
      "Epoch 5/100\n",
      "2932432/2932432 [==============================] - 4s 1us/step - loss: 0.9283 - twenty_one_cm_rmse: 0.1725\n",
      "Epoch 6/100\n",
      "2932432/2932432 [==============================] - 4s 1us/step - loss: 0.9012 - twenty_one_cm_rmse: 0.1554\n",
      "Epoch 7/100\n",
      "2932432/2932432 [==============================] - 4s 1us/step - loss: 0.8542 - twenty_one_cm_rmse: 0.1513\n",
      "Epoch 8/100\n",
      "1466216/2932432 [==============>...............] - ETA: 2s - loss: 0.8292 - twenty_one_cm_rmse: 0.1939"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-17044f177563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kamran/anaconda2/lib/python2.7/site-packages/tensorflow/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/home/kamran/anaconda2/lib/python2.7/site-packages/tensorflow/python/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kamran/anaconda2/lib/python2.7/site-packages/tensorflow/python/keras/backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kamran/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_num,\n",
    "                    epochs=epochs, initial_epoch = initial_epoch,\n",
    "                    verbose=1)\n",
    "initial_epoch += epochs\n",
    "epochs += epochs\n",
    "\n",
    "#save model\n",
    "#model.save(\"../../MPE_examples/saved_keras_models/21/8_params_21_mlp_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.637216691790522e-17\n",
      "(2932432,)\n",
      "-0.027518231\n",
      "(2932432, 1)\n",
      "0.9999999999999993\n",
      "0.11563098\n",
      "rmse ts mean\n"
     ]
    }
   ],
   "source": [
    "print y_train.mean()\n",
    "y_pred = model.predict(x_train)\n",
    "print y_pred.mean()\n",
    "print y_train.var()\n",
    "print y_pred.var()\n",
    "print 'rmse ts mean'\n",
    "print mets.twenty_one_cm_rmse_ts_mean_higher_order(y_train, y_pred, mean, var, n_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print kt.get_activations(x_train, model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.637216691790522e-17\n",
      "0.6600129\n",
      "0.9999999999999993\n",
      "0.10705553\n",
      "rmse ts mean\n",
      "-50.35104929000002\n",
      "-1.8018477\n",
      "5410.769860539998\n",
      "579.2528\n",
      "0.3423576396435991\n"
     ]
    }
   ],
   "source": [
    "print kt.get_gradients(x_train, y_train, model, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
