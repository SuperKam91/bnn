{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/astrophysics/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import keras_forward as kf\n",
    "import tf_forward as tff\n",
    "import keras_models as kms\n",
    "import tf_graphs as tfgs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/astrophysics/anaconda2/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 28 * 28\n",
    "num_outputs = 10\n",
    "m = 1000\n",
    "batch_size = 1000\n",
    "a1_size = 5\n",
    "\n",
    "km = kms.slp_model(num_inputs, num_outputs)\n",
    "km.compile(loss='mse', optimizer='rmsprop')\n",
    "np.random.seed(1337)\n",
    "x_tr = np.random.random((m, num_inputs))\n",
    "y_tr = np.random.randint(size=(m, num_outputs), low = 0, high = 2)\n",
    "num_weights = (num_inputs + 1) * a1_size + (a1_size + 1) * num_outputs\n",
    "\n",
    "km = kf.keras_model(km, x_tr, y_tr, batch_size) \n",
    "km.setup_LL()\n",
    "\n",
    "tf_graph = tfgs.slp_graph\n",
    "layer_sizes = [a1_size]\n",
    "tfm = tff.tf_model(tf_graph, x_tr, y_tr, batch_size, layer_sizes)\n",
    "fit_metric = 'chisq'\n",
    "tfm.setup_LL(fit_metric)\n",
    "\n",
    "n = 1\n",
    "weights = np.random.random((n, num_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 20.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for i in range(n):\n",
    "    tfm(weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 62us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 63us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 61us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 68us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 65us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 64us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 66us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - ETA:  - 0s 49us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 67us/step \n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 82us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 68us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 75us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 52us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 50us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 49us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 51us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 50us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 47us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 44us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 72us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 68us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 121us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 71us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 68us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 63us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 77us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 86us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 65us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 66us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 73us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 62us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 59us/step00 [===========================>..] - ETA: \n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 49us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 67us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 62us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 65us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 66us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 84us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 65us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 66us/step\n",
      "\n",
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 70us/step\n",
      "\n",
      "10 loops, best of 3: 62.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for i in range(n):\n",
    "    km(weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats, cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 137us/step\n",
      "\n",
      "Thu Sep 20 16:17:59 2018    kmProfile.prof\n",
      "\n",
      "         16477 function calls (16409 primitive calls) in 0.164 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       33    0.030    0.001    0.030    0.001 {_pywrap_tensorflow_internal.TF_Run}\n",
      "       34    0.027    0.001    0.027    0.001 socket.py:333(send)\n",
      "       33    0.018    0.001    0.111    0.003 session.py:1042(_run)\n",
      "       33    0.010    0.000    0.021    0.001 session.py:407(__init__)\n",
      "       32    0.009    0.000    0.010    0.000 training.py:383(_slice_arrays)\n",
      "     2998    0.005    0.000    0.005    0.000 {isinstance}\n",
      "      604    0.003    0.000    0.003    0.000 ops.py:1753(name)\n",
      "      236    0.003    0.000    0.005    0.000 ops.py:322(name)\n",
      "        1    0.003    0.003    0.144    0.144 training.py:1324(_test_loop)\n",
      "      104    0.003    0.000    0.003    0.000 {numpy.core.multiarray.array}\n",
      "      716    0.002    0.000    0.003    0.000 ops.py:564(__hash__)\n",
      "      100    0.002    0.000    0.009    0.000 tensor_shape.py:693(is_compatible_with)\n",
      "      168    0.002    0.000    0.004    0.000 ops.py:3325(_as_graph_element_locked)\n",
      "      268    0.001    0.000    0.003    0.000 compat.py:46(as_bytes)\n",
      "      332    0.001    0.000    0.003    0.000 tensor_shape.py:381(as_dimension)\n",
      "       32    0.001    0.000    0.101    0.003 backend.py:2539(__call__)\n",
      "      100    0.001    0.000    0.004    0.000 tensor_shape.py:420(__init__)\n",
      "      534    0.001    0.000    0.001    0.000 {getattr}\n",
      "   101/33    0.001    0.000    0.007    0.000 session.py:221(for_fetch)\n",
      "      268    0.001    0.000    0.001    0.000 {method 'encode' of 'unicode' objects}\n",
      "       32    0.001    0.000    0.030    0.001 generic_utils.py:303(update)\n",
      "       33    0.001    0.000    0.003    0.000 session.py:464(build_results)\n",
      "      716    0.001    0.000    0.001    0.000 {id}\n",
      "      168    0.001    0.000    0.005    0.000 ops.py:3290(as_graph_element)\n",
      "      100    0.001    0.000    0.001    0.000 abc.py:128(__instancecheck__)\n",
      "      100    0.001    0.000    0.002    0.000 session.py:1044(_feed_fn)\n",
      "       33    0.001    0.000    0.039    0.001 session.py:1285(_do_run)\n",
      "       33    0.001    0.000    0.004    0.000 nest.py:200(flatten_dict_items)\n",
      "      624    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "       33    0.001    0.000    0.006    0.000 backend.py:351(get_session)\n",
      "       33    0.001    0.000    0.002    0.000 session.py:301(_uniquify_fetches)\n",
      "      597    0.001    0.000    0.001    0.000 {len}\n",
      "      100    0.001    0.000    0.001    0.000 session_ops.py:253(_get_handle_feeder)\n",
      "      166    0.001    0.000    0.001    0.000 tensor_shape.py:27(__init__)\n",
      "      133    0.001    0.000    0.004    0.000 session.py:1313(<genexpr>)\n",
      "       66    0.001    0.000    0.001    0.000 contextlib.py:21(__exit__)\n",
      "      166    0.001    0.000    0.001    0.000 tensor_shape.py:83(is_compatible_with)\n",
      "       33    0.001    0.000    0.003    0.000 session.py:1408(_update_with_movers)\n",
      "       68    0.001    0.000    0.003    0.000 session.py:257(__init__)\n",
      "       33    0.001    0.000    0.032    0.001 session.py:1317(_run_fn)\n",
      "      100    0.001    0.000    0.005    0.000 tensor_shape.py:844(as_shape)\n",
      "      273    0.001    0.000    0.001    0.000 {method 'get' of 'dict' objects}\n",
      "       33    0.001    0.000    0.003    0.000 backend.py:591(_initialize_variables)\n",
      "      366    0.001    0.000    0.001    0.000 session.py:714(graph)\n",
      "      200    0.001    0.000    0.001    0.000 tensor_shape.py:473(ndims)\n",
      "      101    0.001    0.000    0.001    0.000 ops.py:4803(get_default)\n",
      "      132    0.001    0.000    0.001    0.000 ops.py:4634(get_controller)\n",
      "      168    0.001    0.000    0.001    0.000 ops.py:114(_as_graph_element)\n",
      "      136    0.001    0.000    0.001    0.000 ops.py:317(graph)\n",
      "       33    0.001    0.000    0.112    0.003 session.py:787(run)\n",
      "      134    0.000    0.000    0.001    0.000 ops.py:4617(get_default)\n",
      "      100    0.000    0.000    0.002    0.000 {_pywrap_tensorflow_internal.IsSequence}\n",
      "      171    0.000    0.000    0.000    0.000 {zip}\n",
      "       33    0.000    0.000    0.001    0.000 errors_impl.py:467(__exit__)\n",
      "      200    0.000    0.000    0.000    0.000 _weakrefset.py:70(__contains__)\n",
      "       33    0.000    0.000    0.001    0.000 session.py:353(build_results)\n",
      "       33    0.000    0.000    0.001    0.000 ops.py:3634(get_collection)\n",
      "       68    0.000    0.000    0.001    0.000 session.py:443(_assert_fetchable)\n",
      "       34    0.000    0.000    0.027    0.001 iostream.py:195(schedule)\n",
      "      104    0.000    0.000    0.003    0.000 numeric.py:424(asarray)\n",
      "       66    0.000    0.000    0.002    0.000 session.py:513(_name_list)\n",
      "       66    0.000    0.000    0.001    0.000 ops.py:3528(as_default)\n",
      "       66    0.000    0.000    0.001    0.000 contextlib.py:82(helper)\n",
      "       33    0.000    0.000    0.007    0.000 session.py:340(__init__)\n",
      "      100    0.000    0.000    0.001    0.000 ops.py:4517(is_feedable)\n",
      "      101    0.000    0.000    0.001    0.000 ops.py:4943(get_default_graph)\n",
      "       72    0.000    0.000    0.000    0.000 ops.py:2053(type)\n",
      "      100    0.000    0.000    0.001    0.000 ops.py:429(get_shape)\n",
      "      100    0.000    0.000    0.002    0.000 session_ops.py:273(_get_handle_mover)\n",
      "      100    0.000    0.000    0.002    0.000 nest.py:94(is_sequence)\n",
      "       79    0.000    0.000    0.000    0.000 {hasattr}\n",
      "       21    0.000    0.000    0.004    0.000 iostream.py:366(write)\n",
      "       96    0.000    0.000    0.000    0.000 backend.py:488(is_sparse)\n",
      "       66    0.000    0.000    0.001    0.000 contextlib.py:15(__enter__)\n",
      "      208    0.000    0.000    0.000    0.000 ops.py:307(op)\n",
      "      200    0.000    0.000    0.000    0.000 tensor_shape.py:468(dims)\n",
      "      168    0.000    0.000    0.000    0.000 ops.py:2062(graph)\n",
      "       33    0.000    0.000    0.000    0.000 session.py:1365(_extend_graph)\n",
      "       66    0.000    0.000    0.000    0.000 ops.py:2822(version)\n",
      "       68    0.000    0.000    0.000    0.000 ops.py:4525(is_fetchable)\n",
      "       68    0.000    0.000    0.000    0.000 session.py:293(build_results)\n",
      "       33    0.000    0.000    0.002    0.000 ops.py:5270(get_collection)\n",
      "       33    0.000    0.000    0.000    0.000 context.py:404(in_eager_mode)\n",
      "       33    0.000    0.000    0.000    0.000 ops.py:4704(get_default_session)\n",
      "       33    0.000    0.000    0.000    0.000 errors_impl.py:463(__enter__)\n",
      "       99    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "      100    0.000    0.000    0.000    0.000 dtypes.py:130(as_numpy_dtype)\n",
      "       33    0.000    0.000    0.002    0.000 variables.py:1256(global_variables)\n",
      "      100    0.000    0.000    0.000    0.000 ops.py:334(shape)\n",
      "      108    0.000    0.000    0.000    0.000 ops.py:312(dtype)\n",
      "      100    0.000    0.000    0.000    0.000 session.py:125(<lambda>)\n",
      "       32    0.000    0.000    0.000    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "       33    0.000    0.000    0.000    0.000 c_api_util.py:30(__init__)\n",
      "       33    0.000    0.000    0.001    0.000 ops.py:5512(_assert_collection_is_ok)\n",
      "       66    0.000    0.000    0.000    0.000 contextlib.py:12(__init__)\n",
      "      100    0.000    0.000    0.000    0.000 {iter}\n",
      "       68    0.000    0.000    0.000    0.000 session.py:124(<lambda>)\n",
      "       33    0.000    0.000    0.033    0.001 session.py:1348(_do_call)\n",
      "       38    0.000    0.000    0.000    0.000 threading.py:986(isAlive)\n",
      "       33    0.000    0.000    0.000    0.000 c_api_util.py:33(__del__)\n",
      "       33    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.TF_GetCode}\n",
      "       33    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.TF_NewStatus}\n",
      "        4    0.000    0.000    0.024    0.006 iostream.py:327(flush)\n",
      "       66    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "       21    0.000    0.000    0.000    0.000 {method 'decode' of 'str' objects}\n",
      "       33    0.000    0.000    0.000    0.000 six.py:604(iteritems)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:260(__init__)\n",
      "       76    0.000    0.000    0.000    0.000 tensor_shape.py:78(value)\n",
      "        1    0.000    0.000    0.019    0.019 backend.py:2434(batch_set_value)\n",
      "       34    0.000    0.000    0.000    0.000 {time.time}\n",
      "       33    0.000    0.000    0.000    0.000 context.py:195(in_eager_mode)\n",
      "       21    0.000    0.000    0.000    0.000 {_codecs.utf_8_decode}\n",
      "       68    0.000    0.000    0.000    0.000 session.py:290(unique_fetches)\n",
      "       21    0.000    0.000    0.000    0.000 iostream.py:300(_is_master_process)\n",
      "       21    0.000    0.000    0.000    0.000 utf_8.py:15(decode)\n",
      "       34    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        1    0.000    0.000    0.019    0.019 keras_forward.py:150(set_k_weights)\n",
      "       33    0.000    0.000    0.000    0.000 context.py:369(context)\n",
      "       33    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.TF_DeleteStatus}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:561(__init__)\n",
      "        1    0.000    0.000    0.145    0.145 keras_forward.py:43(calc_gauss_LL)\n",
      "       33    0.000    0.000    0.000    0.000 session.py:350(unique_fetches)\n",
      "       21    0.000    0.000    0.001    0.000 iostream.py:313(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 training.py:39(_standardize_input_data)\n",
      "       33    0.000    0.000    0.000    0.000 {method 'iteritems' of 'dict' objects}\n",
      "       32    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 training.py:368(_make_batches)\n",
      "       38    0.000    0.000    0.000    0.000 threading.py:570(isSet)\n",
      "        1    0.000    0.000    0.019    0.019 topology.py:760(set_weights)\n",
      "        4    0.000    0.000    0.000    0.000 fromnumeric.py:2456(prod)\n",
      "       34    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 training.py:1400(_standardize_user_data)\n",
      "       33    0.000    0.000    0.000    0.000 session.py:448(fetches)\n",
      "       32    0.000    0.000    0.000    0.000 {min}\n",
      "       33    0.000    0.000    0.000    0.000 session.py:456(targets)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:201(weights)\n",
      "        1    0.000    0.000    0.145    0.145 training.py:1680(evaluate)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:542(Event)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:242(Condition)\n",
      "        8    0.000    0.000    0.000    0.000 variables.py:903(dtype)\n",
      "        2    0.000    0.000    0.000    0.000 generic_utils.py:286(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 backend.py:818(dtype)\n",
      "        4    0.000    0.000    0.000    0.000 dtypes.py:583(as_dtype)\n",
      "       21    0.000    0.000    0.000    0.000 {posix.getpid}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:597(wait)\n",
      "        8    0.000    0.000    0.000    0.000 threading.py:59(__init__)\n",
      "        1    0.000    0.000    0.164    0.164 keras_forward.py:165(__call__)\n",
      "        1    0.000    0.000    0.164    0.164 <string>:1(<module>)\n",
      "        4    0.000    0.000    0.000    0.000 _methods.py:34(_prod)\n",
      "        1    0.000    0.000    0.000    0.000 training.py:212(_check_array_lengths)\n",
      "        4    0.000    0.000    0.000    0.000 dtypes.py:103(base_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:285(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.arange}\n",
      "        1    0.000    0.000    0.000    0.000 training.py:477(_standardize_weights)\n",
      "        1    0.000    0.000    0.019    0.019 keras_forward.py:147(set_model_weights)\n",
      "        3    0.000    0.000    0.000    0.000 training.py:224(set_of_lengths)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:182(trainable_weights)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:288(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}\n",
      "        8    0.000    0.000    0.000    0.000 dtypes.py:284(name)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:146(ones)\n",
      "        4    0.000    0.000    0.000    0.000 {thread.allocate_lock}\n",
      "        1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.copyto}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 topology.py:721(stateful)\n",
      "        6    0.000    0.000    0.000    0.000 {range}\n",
      "        1    0.000    0.000    0.000    0.000 training.py:259(_check_loss_and_target_compatibility)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:186(non_trainable_weights)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'isatty' of '_io._IOBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__enter__' of 'thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 topology.py:716(uses_learning_phase)\n",
      "        4    0.000    0.000    0.000    0.000 dtypes.py:90(_is_ref_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 {imp.lock_held}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of 'thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:309(closed)\n",
      "        1    0.000    0.000    0.000    0.000 keras_forward.py:144(set_oned_weights)\n",
      "        2    0.000    0.000    0.000    0.000 training.py:158(_standardize_sample_or_class_weights)\n",
      "        1    0.000    0.000    0.000    0.000 training.py:989(_make_test_function)\n",
      "        1    0.000    0.000    0.000    0.000 training.py:1024(_check_num_samples)\n",
      "        1    0.000    0.000    0.000    0.000 training.py:202(_standardize_class_weights)\n",
      "        1    0.000    0.000    0.000    0.000 training.py:207(_standardize_sample_weights)\n",
      "        1    0.000    0.000    0.000    0.000 keras_forward.py:141(set_weights)\n",
      "        1    0.000    0.000    0.000    0.000 keras_forward.py:101(get_weight_shapes)\n",
      "        1    0.000    0.000    0.000    0.000 keras_forward.py:176(get_batch)\n",
      "        2    0.000    0.000    0.000    0.000 {any}\n",
      "        1    0.000    0.000    0.000    0.000 backend.py:145(floatx)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats instance at 0x7f3bdc6c2368>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cProfile.runctx(\"km(weights[0])\", globals(), locals(), \"kmProfile.prof\")\n",
    "\n",
    "s = pstats.Stats(\"kmProfile.prof\")\n",
    "s.strip_dirs().sort_stats(\"time\").print_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep 20 16:17:30 2018    tfmProfile.prof\n",
      "\n",
      "         1271 function calls in 0.068 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.025    0.025    0.025    0.025 {_pywrap_tensorflow_internal.TF_Run}\n",
      "      128    0.009    0.000    0.009    0.000 {isinstance}\n",
      "       34    0.007    0.000    0.007    0.000 ops.py:564(__hash__)\n",
      "        1    0.007    0.007    0.007    0.007 {method 'SerializeToString' of 'google.protobuf.pyext._message.CMessage' objects}\n",
      "        1    0.006    0.006    0.006    0.006 {_pywrap_tensorflow_internal.TF_ExtendGraph}\n",
      "      106    0.005    0.000    0.005    0.000 {method 'ByteSize' of 'google.protobuf.pyext._message.CMessage' objects}\n",
      "      106    0.002    0.000    0.002    0.000 {method 'extend' of 'google.protobuf.pyext._message.RepeatedCompositeContainer' objects}\n",
      "        1    0.001    0.001    0.009    0.009 ops.py:2925(_as_graph_def)\n",
      "        1    0.001    0.001    0.001    0.001 {_pywrap_tensorflow_internal.TF_DeleteDeprecatedSession}\n",
      "        1    0.000    0.000    0.048    0.048 session.py:1317(_run_fn)\n",
      "        1    0.000    0.000    0.067    0.067 session.py:1042(_run)\n",
      "      212    0.000    0.000    0.000    0.000 ops.py:2067(node_def)\n",
      "        6    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}\n",
      "      106    0.000    0.000    0.000    0.000 ops.py:1969(outputs)\n",
      "       13    0.000    0.000    0.000    0.000 ops.py:322(name)\n",
      "        1    0.000    0.000    0.000    0.000 {sorted}\n",
      "       32    0.000    0.000    0.000    0.000 ops.py:1753(name)\n",
      "       20    0.000    0.000    0.009    0.000 tensor_shape.py:381(as_dimension)\n",
      "        1    0.000    0.000    0.000    0.000 session.py:257(__init__)\n",
      "        1    0.000    0.000    0.022    0.022 session.py:1365(_extend_graph)\n",
      "        6    0.000    0.000    0.010    0.002 tensor_shape.py:693(is_compatible_with)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        6    0.000    0.000    0.009    0.002 tensor_shape.py:420(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.TF_NewDeprecatedSession}\n",
      "       13    0.000    0.000    0.000    0.000 abc.py:128(__instancecheck__)\n",
      "        1    0.000    0.000    0.007    0.007 nest.py:200(flatten_dict_items)\n",
      "       14    0.000    0.000    0.000    0.000 compat.py:46(as_bytes)\n",
      "        7    0.000    0.000    0.000    0.000 ops.py:3325(_as_graph_element_locked)\n",
      "       10    0.000    0.000    0.009    0.001 tensor_shape.py:27(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 errors_impl.py:467(__exit__)\n",
      "       10    0.000    0.000    0.000    0.000 tensor_shape.py:83(is_compatible_with)\n",
      "        1    0.000    0.000    0.000    0.000 session.py:407(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 tf_forward.py:96(get_tf_weights)\n",
      "        6    0.000    0.000    0.000    0.000 session.py:1044(_feed_fn)\n",
      "       13    0.000    0.000    0.000    0.000 {method 'encode' of 'unicode' objects}\n",
      "        7    0.000    0.000    0.000    0.000 ops.py:3290(as_graph_element)\n",
      "       20    0.000    0.000    0.000    0.000 {getattr}\n",
      "        4    0.000    0.000    0.000    0.000 fromnumeric.py:2456(prod)\n",
      "        1    0.000    0.000    0.068    0.068 tf_forward.py:85(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 session.py:565(__init__)\n",
      "       34    0.000    0.000    0.000    0.000 {id}\n",
      "       23    0.000    0.000    0.000    0.000 _weakrefset.py:70(__contains__)\n",
      "        6    0.000    0.000    0.000    0.000 session_ops.py:253(_get_handle_feeder)\n",
      "        7    0.000    0.000    0.000    0.000 session.py:1313(<genexpr>)\n",
      "        1    0.000    0.000    0.048    0.048 session.py:1285(_do_run)\n",
      "        6    0.000    0.000    0.009    0.002 tensor_shape.py:844(as_shape)\n",
      "        1    0.000    0.000    0.000    0.000 session.py:464(build_results)\n",
      "       12    0.000    0.000    0.000    0.000 tensor_shape.py:473(ndims)\n",
      "       19    0.000    0.000    0.000    0.000 session.py:714(graph)\n",
      "        1    0.000    0.000    0.000    0.000 session.py:1408(_update_with_movers)\n",
      "        6    0.000    0.000    0.000    0.000 numeric.py:424(asarray)\n",
      "        2    0.000    0.000    0.000    0.000 ops.py:4617(get_default)\n",
      "        6    0.000    0.000    0.000    0.000 ops.py:4517(is_feedable)\n",
      "        2    0.000    0.000    0.000    0.000 ops.py:4943(get_default_graph)\n",
      "       19    0.000    0.000    0.000    0.000 {len}\n",
      "        4    0.000    0.000    0.000    0.000 errors_impl.py:463(__enter__)\n",
      "        7    0.000    0.000    0.000    0.000 ops.py:317(graph)\n",
      "        1    0.000    0.000    0.000    0.000 session.py:672(close)\n",
      "       20    0.000    0.000    0.000    0.000 tensor_shape.py:78(value)\n",
      "        7    0.000    0.000    0.000    0.000 ops.py:114(_as_graph_element)\n",
      "        5    0.000    0.000    0.000    0.000 c_api_util.py:33(__del__)\n",
      "        2    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.Flatten}\n",
      "        4    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.TF_GetCode}\n",
      "        6    0.000    0.000    0.000    0.000 ops.py:429(get_shape)\n",
      "        2    0.000    0.000    0.000    0.000 ops.py:4803(get_default)\n",
      "        1    0.000    0.000    0.068    0.068 <string>:1(<module>)\n",
      "        6    0.000    0.000    0.000    0.000 session_ops.py:273(_get_handle_mover)\n",
      "        5    0.000    0.000    0.000    0.000 c_api_util.py:30(__init__)\n",
      "        1    0.000    0.000    0.067    0.067 session.py:787(run)\n",
      "        7    0.000    0.000    0.000    0.000 {zip}\n",
      "        1    0.000    0.000    0.001    0.001 session.py:694(__del__)\n",
      "        5    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.TF_NewStatus}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google.protobuf.pyext._message.CMessage' objects}\n",
      "       12    0.000    0.000    0.000    0.000 tensor_shape.py:468(dims)\n",
      "        3    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.IsSequence}\n",
      "        2    0.000    0.000    0.000    0.000 ops.py:4634(get_controller)\n",
      "        1    0.000    0.000    0.000    0.000 session.py:221(for_fetch)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 _methods.py:34(_prod)\n",
      "        6    0.000    0.000    0.000    0.000 ops.py:334(shape)\n",
      "        9    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        9    0.000    0.000    0.000    0.000 ops.py:307(op)\n",
      "        6    0.000    0.000    0.000    0.000 dtypes.py:130(as_numpy_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 contextlib.py:21(__exit__)\n",
      "        6    0.000    0.000    0.000    0.000 ops.py:312(dtype)\n",
      "        7    0.000    0.000    0.000    0.000 ops.py:2062(graph)\n",
      "        5    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.TF_DeleteStatus}\n",
      "        6    0.000    0.000    0.000    0.000 session.py:125(<lambda>)\n",
      "        3    0.000    0.000    0.000    0.000 nest.py:94(is_sequence)\n",
      "        1    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal._TF_NewSessionOptions}\n",
      "        1    0.000    0.000    0.000    0.000 contextlib.py:82(helper)\n",
      "        6    0.000    0.000    0.000    0.000 {iter}\n",
      "        2    0.000    0.000    0.000    0.000 ops.py:2822(version)\n",
      "        1    0.000    0.000    0.000    0.000 session.py:1488(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 ops.py:3528(as_default)\n",
      "        2    0.000    0.000    0.000    0.000 ops.py:2053(type)\n",
      "        1    0.000    0.000    0.000    0.000 pywrap_tensorflow_internal.py:1343(TF_NewSessionOptions)\n",
      "        2    0.000    0.000    0.000    0.000 nest.py:107(flatten)\n",
      "        2    0.000    0.000    0.000    0.000 session.py:513(_name_list)\n",
      "        1    0.000    0.000    0.000    0.000 collections.py:121(values)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 ops.py:2911(_copy_functions_to_graph_def)\n",
      "        1    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.TF_DeleteSessionOptions}\n",
      "        1    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.TF_CloseDeprecatedSession}\n",
      "        1    0.000    0.000    0.048    0.048 session.py:1348(_do_call)\n",
      "        1    0.000    0.000    0.000    0.000 contextlib.py:15(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal._TF_SetTarget}\n",
      "        1    0.000    0.000    0.000    0.000 six.py:604(iteritems)\n",
      "        1    0.000    0.000    0.000    0.000 ops.py:4525(is_fetchable)\n",
      "        1    0.000    0.000    0.000    0.000 session.py:293(build_results)\n",
      "        1    0.000    0.000    0.000    0.000 session.py:443(_assert_fetchable)\n",
      "        1    0.000    0.000    0.000    0.000 tf_forward.py:108(get_batch)\n",
      "        1    0.000    0.000    0.000    0.000 session.py:124(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 collections.py:90(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 ops.py:4810(_GetGlobalDefaultGraph)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'iteritems' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {thread.allocate_lock}\n",
      "        1    0.000    0.000    0.000    0.000 session.py:448(fetches)\n",
      "        1    0.000    0.000    0.000    0.000 contextlib.py:12(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 session.py:456(targets)\n",
      "        1    0.000    0.000    0.000    0.000 session.py:290(unique_fetches)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats instance at 0x7f3bdc77d6c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cProfile.runctx(\"tfm(weights[0])\", globals(), locals(), \"tfmProfile.prof\")\n",
    "\n",
    "s = pstats.Stats(\"tfmProfile.prof\")\n",
    "s.strip_dirs().sort_stats(\"time\").print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
