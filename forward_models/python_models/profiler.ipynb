{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/astrophysics/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Could not preload libmpi.so.If you are running with MPI, this may cause segfaults\n"
     ]
    }
   ],
   "source": [
    "import keras_forward as kf\n",
    "import tf_forward as tff\n",
    "import np_forward as npf\n",
    "import keras_models as kms\n",
    "import tf_graphs as tfgs\n",
    "import np_models as nnns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/astrophysics/anaconda2/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "('Last dead point:', array([ 2.84459696e-01, -8.47359259e-01, -9.20544547e+02, -9.20302934e+02]))\n",
      "('Last dead point:', array([ 8.25332044e-01, -5.85127787e-01, -9.20220323e+02, -9.19267739e+02]))\n",
      "('Last dead point:', array([-3.19338179e-01,  7.50469656e-01, -9.19122493e+02, -9.19038614e+02]))\n",
      "('Last dead point:', array([ 6.79165283e-01, -2.38415255e-01, -9.19052766e+02, -9.18965030e+02]))\n",
      "('Last dead point:', array([-1.88818494e-01,  9.40456202e-01, -9.18952639e+02, -9.18945201e+02]))\n",
      "('Last dead point:', array([ 8.74816389e-01, -2.14785780e-01, -9.19448071e+02, -9.18940877e+02]))\n",
      "('Last dead point:', array([-2.06192020e-01,  7.75661722e-01, -9.18939432e+02, -9.18939363e+02]))\n",
      "('Last dead point:', array([ 7.58931541e-01, -1.95913441e-01, -9.18938938e+02, -9.18938901e+02]))\n",
      "('Last dead point:', array([-1.99990085e-01,  8.00944484e-01, -9.18938831e+02, -9.18938533e+02]))\n",
      "('Last dead point:', array([ 1.60321623e-01, -3.28472374e-01, -2.90961100e+03, -9.20231317e+02]))\n",
      "('Last dead point:', array([-5.91454578e-01,  8.52233256e-01, -9.19364019e+02, -9.19263620e+02]))\n",
      "('Last dead point:', array([ 5.56753479e-01, -2.83260437e-01, -9.19375621e+02, -9.19053739e+02]))\n",
      "('Last dead point:', array([-1.85642050e-01,  5.01297310e-01, -9.19001030e+02, -9.18967251e+02]))\n",
      "('Last dead point:', array([-1.77602310e-01,  7.39271461e-01, -9.19009893e+02, -9.18945372e+02]))\n",
      "('Last dead point:', array([-2.08859784e-01,  9.18714376e-01, -9.19044380e+02, -9.18940691e+02]))\n",
      "('Last dead point:', array([-1.96247575e-01,  7.35729468e-01, -9.18940176e+02, -9.18939338e+02]))\n",
      "('Last dead point:', array([ 7.94941222e-01, -1.95308982e-01, -9.18940676e+02, -9.18938813e+02]))\n",
      "('Last dead point:', array([-2.00149133e-01,  8.01063427e-01, -9.18938794e+02, -9.18938534e+02]))\n",
      "('Last dead point:', array([-4.64838480e-01,  2.25643659e-01, -2.91095842e+03, -9.20122757e+02]))\n",
      "('Last dead point:', array([ 8.44917185e-01, -5.64772916e-01, -9.19384297e+02, -9.19247008e+02]))\n",
      "('Last dead point:', array([ 7.18244085e-01, -2.98747670e-01, -9.19064835e+02, -9.19021612e+02]))\n",
      "('Last dead point:', array([-1.69797725e-01,  9.11048666e-01, -9.18989050e+02, -9.18960048e+02]))\n",
      "('Last dead point:', array([-2.23615850e-01,  9.50644041e-01, -9.18955845e+02, -9.18944695e+02]))\n",
      "('Last dead point:', array([-2.06114305e-01,  9.29092999e-01, -9.18941591e+02, -9.18940858e+02]))\n",
      "('Last dead point:', array([-2.08572792e-01,  8.44352071e-01, -9.18941792e+02, -9.18939364e+02]))\n",
      "('Last dead point:', array([-2.02010161e-01,  7.72431252e-01, -9.18938926e+02, -9.18938830e+02]))\n",
      "('Last dead point:', array([ 7.99992971e-01, -1.99962644e-01, -9.18938798e+02, -9.18938533e+02]))\n",
      "('Last dead point:', array([-6.81438407e-01,  3.53847390e-01, -9.65412983e+02, -9.19892766e+02]))\n"
     ]
    }
   ],
   "source": [
    "%timeit kf.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/astrophysics/anaconda2/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 28 * 28\n",
    "num_outputs = 10\n",
    "m = 1000\n",
    "batch_size = 1000\n",
    "a1_size = 5\n",
    "\n",
    "np.random.seed(1337)\n",
    "x_tr = np.random.random((m, num_inputs))\n",
    "y_tr = np.random.randint(size=(m, num_outputs), low = 0, high = 2)\n",
    "\n",
    "a1_size = 5\n",
    "layer_sizes = [5]\n",
    "\n",
    "batch_size = x_tr.shape[0]\n",
    "\n",
    "km = kf.keras_model(model, x_tr, y_tr, batch_size)\n",
    "loss = 'mse' \n",
    "km.setup_LL(loss)\n",
    "\n",
    "tf_graph = tfgs.slp_graph\n",
    "layer_sizes = [a1_size]\n",
    "tfm = tff.tf_model(tf_graph, x_tr, y_tr, batch_size, layer_sizes)\n",
    "fit_metric = 'chisq'\n",
    "tfm.setup_LL(fit_metric)\n",
    "\n",
    "np_nn = nnns.slp_nn\n",
    "layer_sizes = [a1_size]\n",
    "npm = npf.np_model(np_nn, x_tr, y_tr, batch_size, layer_sizes)\n",
    "ll_type = 'gauss'\n",
    "npm.setup_LL(ll_type)\n",
    "\n",
    "n = 1\n",
    "weights = np.random.random((n, num_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats, cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================]1000/1000 [==============================] - 0s 137us/step\n",
      "\n",
      "Thu Sep 20 16:17:59 2018    kmProfile.prof\n",
      "\n",
      "         16477 function calls (16409 primitive calls) in 0.164 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       33    0.030    0.001    0.030    0.001 {_pywrap_tensorflow_internal.TF_Run}\n",
      "       34    0.027    0.001    0.027    0.001 socket.py:333(send)\n",
      "       33    0.018    0.001    0.111    0.003 session.py:1042(_run)\n",
      "       33    0.010    0.000    0.021    0.001 session.py:407(__init__)\n",
      "       32    0.009    0.000    0.010    0.000 training.py:383(_slice_arrays)\n",
      "     2998    0.005    0.000    0.005    0.000 {isinstance}\n",
      "      604    0.003    0.000    0.003    0.000 ops.py:1753(name)\n",
      "      236    0.003    0.000    0.005    0.000 ops.py:322(name)\n",
      "        1    0.003    0.003    0.144    0.144 training.py:1324(_test_loop)\n",
      "      104    0.003    0.000    0.003    0.000 {numpy.core.multiarray.array}\n",
      "      716    0.002    0.000    0.003    0.000 ops.py:564(__hash__)\n",
      "      100    0.002    0.000    0.009    0.000 tensor_shape.py:693(is_compatible_with)\n",
      "      168    0.002    0.000    0.004    0.000 ops.py:3325(_as_graph_element_locked)\n",
      "      268    0.001    0.000    0.003    0.000 compat.py:46(as_bytes)\n",
      "      332    0.001    0.000    0.003    0.000 tensor_shape.py:381(as_dimension)\n",
      "       32    0.001    0.000    0.101    0.003 backend.py:2539(__call__)\n",
      "      100    0.001    0.000    0.004    0.000 tensor_shape.py:420(__init__)\n",
      "      534    0.001    0.000    0.001    0.000 {getattr}\n",
      "   101/33    0.001    0.000    0.007    0.000 session.py:221(for_fetch)\n",
      "      268    0.001    0.000    0.001    0.000 {method 'encode' of 'unicode' objects}\n",
      "       32    0.001    0.000    0.030    0.001 generic_utils.py:303(update)\n",
      "       33    0.001    0.000    0.003    0.000 session.py:464(build_results)\n",
      "      716    0.001    0.000    0.001    0.000 {id}\n",
      "      168    0.001    0.000    0.005    0.000 ops.py:3290(as_graph_element)\n",
      "      100    0.001    0.000    0.001    0.000 abc.py:128(__instancecheck__)\n",
      "      100    0.001    0.000    0.002    0.000 session.py:1044(_feed_fn)\n",
      "       33    0.001    0.000    0.039    0.001 session.py:1285(_do_run)\n",
      "       33    0.001    0.000    0.004    0.000 nest.py:200(flatten_dict_items)\n",
      "      624    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "       33    0.001    0.000    0.006    0.000 backend.py:351(get_session)\n",
      "       33    0.001    0.000    0.002    0.000 session.py:301(_uniquify_fetches)\n",
      "      597    0.001    0.000    0.001    0.000 {len}\n",
      "      100    0.001    0.000    0.001    0.000 session_ops.py:253(_get_handle_feeder)\n",
      "      166    0.001    0.000    0.001    0.000 tensor_shape.py:27(__init__)\n",
      "      133    0.001    0.000    0.004    0.000 session.py:1313(<genexpr>)\n",
      "       66    0.001    0.000    0.001    0.000 contextlib.py:21(__exit__)\n",
      "      166    0.001    0.000    0.001    0.000 tensor_shape.py:83(is_compatible_with)\n",
      "       33    0.001    0.000    0.003    0.000 session.py:1408(_update_with_movers)\n",
      "       68    0.001    0.000    0.003    0.000 session.py:257(__init__)\n",
      "       33    0.001    0.000    0.032    0.001 session.py:1317(_run_fn)\n",
      "      100    0.001    0.000    0.005    0.000 tensor_shape.py:844(as_shape)\n",
      "      273    0.001    0.000    0.001    0.000 {method 'get' of 'dict' objects}\n",
      "       33    0.001    0.000    0.003    0.000 backend.py:591(_initialize_variables)\n",
      "      366    0.001    0.000    0.001    0.000 session.py:714(graph)\n",
      "      200    0.001    0.000    0.001    0.000 tensor_shape.py:473(ndims)\n",
      "      101    0.001    0.000    0.001    0.000 ops.py:4803(get_default)\n",
      "      132    0.001    0.000    0.001    0.000 ops.py:4634(get_controller)\n",
      "      168    0.001    0.000    0.001    0.000 ops.py:114(_as_graph_element)\n",
      "      136    0.001    0.000    0.001    0.000 ops.py:317(graph)\n",
      "       33    0.001    0.000    0.112    0.003 session.py:787(run)\n",
      "      134    0.000    0.000    0.001    0.000 ops.py:4617(get_default)\n",
      "      100    0.000    0.000    0.002    0.000 {_pywrap_tensorflow_internal.IsSequence}\n",
      "      171    0.000    0.000    0.000    0.000 {zip}\n",
      "       33    0.000    0.000    0.001    0.000 errors_impl.py:467(__exit__)\n",
      "      200    0.000    0.000    0.000    0.000 _weakrefset.py:70(__contains__)\n",
      "       33    0.000    0.000    0.001    0.000 session.py:353(build_results)\n",
      "       33    0.000    0.000    0.001    0.000 ops.py:3634(get_collection)\n",
      "       68    0.000    0.000    0.001    0.000 session.py:443(_assert_fetchable)\n",
      "       34    0.000    0.000    0.027    0.001 iostream.py:195(schedule)\n",
      "      104    0.000    0.000    0.003    0.000 numeric.py:424(asarray)\n",
      "       66    0.000    0.000    0.002    0.000 session.py:513(_name_list)\n",
      "       66    0.000    0.000    0.001    0.000 ops.py:3528(as_default)\n",
      "       66    0.000    0.000    0.001    0.000 contextlib.py:82(helper)\n",
      "       33    0.000    0.000    0.007    0.000 session.py:340(__init__)\n",
      "      100    0.000    0.000    0.001    0.000 ops.py:4517(is_feedable)\n",
      "      101    0.000    0.000    0.001    0.000 ops.py:4943(get_default_graph)\n",
      "       72    0.000    0.000    0.000    0.000 ops.py:2053(type)\n",
      "      100    0.000    0.000    0.001    0.000 ops.py:429(get_shape)\n",
      "      100    0.000    0.000    0.002    0.000 session_ops.py:273(_get_handle_mover)\n",
      "      100    0.000    0.000    0.002    0.000 nest.py:94(is_sequence)\n",
      "       79    0.000    0.000    0.000    0.000 {hasattr}\n",
      "       21    0.000    0.000    0.004    0.000 iostream.py:366(write)\n",
      "       96    0.000    0.000    0.000    0.000 backend.py:488(is_sparse)\n",
      "       66    0.000    0.000    0.001    0.000 contextlib.py:15(__enter__)\n",
      "      208    0.000    0.000    0.000    0.000 ops.py:307(op)\n",
      "      200    0.000    0.000    0.000    0.000 tensor_shape.py:468(dims)\n",
      "      168    0.000    0.000    0.000    0.000 ops.py:2062(graph)\n",
      "       33    0.000    0.000    0.000    0.000 session.py:1365(_extend_graph)\n",
      "       66    0.000    0.000    0.000    0.000 ops.py:2822(version)\n",
      "       68    0.000    0.000    0.000    0.000 ops.py:4525(is_fetchable)\n",
      "       68    0.000    0.000    0.000    0.000 session.py:293(build_results)\n",
      "       33    0.000    0.000    0.002    0.000 ops.py:5270(get_collection)\n",
      "       33    0.000    0.000    0.000    0.000 context.py:404(in_eager_mode)\n",
      "       33    0.000    0.000    0.000    0.000 ops.py:4704(get_default_session)\n",
      "       33    0.000    0.000    0.000    0.000 errors_impl.py:463(__enter__)\n",
      "       99    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "      100    0.000    0.000    0.000    0.000 dtypes.py:130(as_numpy_dtype)\n",
      "       33    0.000    0.000    0.002    0.000 variables.py:1256(global_variables)\n",
      "      100    0.000    0.000    0.000    0.000 ops.py:334(shape)\n",
      "      108    0.000    0.000    0.000    0.000 ops.py:312(dtype)\n",
      "      100    0.000    0.000    0.000    0.000 session.py:125(<lambda>)\n",
      "       32    0.000    0.000    0.000    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "       33    0.000    0.000    0.000    0.000 c_api_util.py:30(__init__)\n",
      "       33    0.000    0.000    0.001    0.000 ops.py:5512(_assert_collection_is_ok)\n",
      "       66    0.000    0.000    0.000    0.000 contextlib.py:12(__init__)\n",
      "      100    0.000    0.000    0.000    0.000 {iter}\n",
      "       68    0.000    0.000    0.000    0.000 session.py:124(<lambda>)\n",
      "       33    0.000    0.000    0.033    0.001 session.py:1348(_do_call)\n",
      "       38    0.000    0.000    0.000    0.000 threading.py:986(isAlive)\n",
      "       33    0.000    0.000    0.000    0.000 c_api_util.py:33(__del__)\n",
      "       33    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.TF_GetCode}\n",
      "       33    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.TF_NewStatus}\n",
      "        4    0.000    0.000    0.024    0.006 iostream.py:327(flush)\n",
      "       66    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "       21    0.000    0.000    0.000    0.000 {method 'decode' of 'str' objects}\n",
      "       33    0.000    0.000    0.000    0.000 six.py:604(iteritems)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:260(__init__)\n",
      "       76    0.000    0.000    0.000    0.000 tensor_shape.py:78(value)\n",
      "        1    0.000    0.000    0.019    0.019 backend.py:2434(batch_set_value)\n",
      "       34    0.000    0.000    0.000    0.000 {time.time}\n",
      "       33    0.000    0.000    0.000    0.000 context.py:195(in_eager_mode)\n",
      "       21    0.000    0.000    0.000    0.000 {_codecs.utf_8_decode}\n",
      "       68    0.000    0.000    0.000    0.000 session.py:290(unique_fetches)\n",
      "       21    0.000    0.000    0.000    0.000 iostream.py:300(_is_master_process)\n",
      "       21    0.000    0.000    0.000    0.000 utf_8.py:15(decode)\n",
      "       34    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        1    0.000    0.000    0.019    0.019 keras_forward.py:150(set_k_weights)\n",
      "       33    0.000    0.000    0.000    0.000 context.py:369(context)\n",
      "       33    0.000    0.000    0.000    0.000 {_pywrap_tensorflow_internal.TF_DeleteStatus}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:561(__init__)\n",
      "        1    0.000    0.000    0.145    0.145 keras_forward.py:43(calc_gauss_LL)\n",
      "       33    0.000    0.000    0.000    0.000 session.py:350(unique_fetches)\n",
      "       21    0.000    0.000    0.001    0.000 iostream.py:313(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 training.py:39(_standardize_input_data)\n",
      "       33    0.000    0.000    0.000    0.000 {method 'iteritems' of 'dict' objects}\n",
      "       32    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 training.py:368(_make_batches)\n",
      "       38    0.000    0.000    0.000    0.000 threading.py:570(isSet)\n",
      "        1    0.000    0.000    0.019    0.019 topology.py:760(set_weights)\n",
      "        4    0.000    0.000    0.000    0.000 fromnumeric.py:2456(prod)\n",
      "       34    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 training.py:1400(_standardize_user_data)\n",
      "       33    0.000    0.000    0.000    0.000 session.py:448(fetches)\n",
      "       32    0.000    0.000    0.000    0.000 {min}\n",
      "       33    0.000    0.000    0.000    0.000 session.py:456(targets)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:201(weights)\n",
      "        1    0.000    0.000    0.145    0.145 training.py:1680(evaluate)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:542(Event)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:242(Condition)\n",
      "        8    0.000    0.000    0.000    0.000 variables.py:903(dtype)\n",
      "        2    0.000    0.000    0.000    0.000 generic_utils.py:286(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 backend.py:818(dtype)\n",
      "        4    0.000    0.000    0.000    0.000 dtypes.py:583(as_dtype)\n",
      "       21    0.000    0.000    0.000    0.000 {posix.getpid}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:597(wait)\n",
      "        8    0.000    0.000    0.000    0.000 threading.py:59(__init__)\n",
      "        1    0.000    0.000    0.164    0.164 keras_forward.py:165(__call__)\n",
      "        1    0.000    0.000    0.164    0.164 <string>:1(<module>)\n",
      "        4    0.000    0.000    0.000    0.000 _methods.py:34(_prod)\n",
      "        1    0.000    0.000    0.000    0.000 training.py:212(_check_array_lengths)\n",
      "        4    0.000    0.000    0.000    0.000 dtypes.py:103(base_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:285(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.arange}\n",
      "        1    0.000    0.000    0.000    0.000 training.py:477(_standardize_weights)\n",
      "        1    0.000    0.000    0.019    0.019 keras_forward.py:147(set_model_weights)\n",
      "        3    0.000    0.000    0.000    0.000 training.py:224(set_of_lengths)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:182(trainable_weights)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:288(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}\n",
      "        8    0.000    0.000    0.000    0.000 dtypes.py:284(name)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:146(ones)\n",
      "        4    0.000    0.000    0.000    0.000 {thread.allocate_lock}\n",
      "        1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.copyto}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 topology.py:721(stateful)\n",
      "        6    0.000    0.000    0.000    0.000 {range}\n",
      "        1    0.000    0.000    0.000    0.000 training.py:259(_check_loss_and_target_compatibility)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:186(non_trainable_weights)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'isatty' of '_io._IOBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__enter__' of 'thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 topology.py:716(uses_learning_phase)\n",
      "        4    0.000    0.000    0.000    0.000 dtypes.py:90(_is_ref_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 {imp.lock_held}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of 'thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:309(closed)\n",
      "        1    0.000    0.000    0.000    0.000 keras_forward.py:144(set_oned_weights)\n",
      "        2    0.000    0.000    0.000    0.000 training.py:158(_standardize_sample_or_class_weights)\n",
      "        1    0.000    0.000    0.000    0.000 training.py:989(_make_test_function)\n",
      "        1    0.000    0.000    0.000    0.000 training.py:1024(_check_num_samples)\n",
      "        1    0.000    0.000    0.000    0.000 training.py:202(_standardize_class_weights)\n",
      "        1    0.000    0.000    0.000    0.000 training.py:207(_standardize_sample_weights)\n",
      "        1    0.000    0.000    0.000    0.000 keras_forward.py:141(set_weights)\n",
      "        1    0.000    0.000    0.000    0.000 keras_forward.py:101(get_weight_shapes)\n",
      "        1    0.000    0.000    0.000    0.000 keras_forward.py:176(get_batch)\n",
      "        2    0.000    0.000    0.000    0.000 {any}\n",
      "        1    0.000    0.000    0.000    0.000 backend.py:145(floatx)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats instance at 0x7f3bdc6c2368>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cProfile.runctx(function to be profiled, globals(), locals(), name of prof file)\n",
    "\n",
    "s = pstats.Stats(name of prof file)\n",
    "s.strip_dirs().sort_stats(\"time\").print_stats()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
